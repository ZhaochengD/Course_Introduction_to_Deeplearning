{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "# import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../jester/20bn-jester-v1/*'\n",
    "num_classes = 2\n",
    "num_worker = 0\n",
    "batch_size = 4\n",
    "scales = [1, 1/2**(1/4), 1/2**(1/2), 1/2**(3/4), 1/2]\n",
    "sample_size = 224\n",
    "sample_duration = 16\n",
    "rgb_mean = (114.7748/255, 107.7354/255, 99.4750/255)\n",
    "rgb_std = (38.7568578/255, 37.88248729/255, 40.02898126/255)\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_path(root):\n",
    "    video_dictionary = sorted(glob.glob(root))\n",
    "    all_path = []\n",
    "    for video_path in video_dictionary:\n",
    "        file_list = sorted(glob.glob(video_path + '/*'))\n",
    "        all_path.append(file_list)\n",
    "    return all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Swiping Left',\n",
       " 'Swiping Right',\n",
       " 'Swiping Down',\n",
       " 'Swiping Up',\n",
       " 'Pushing Hand Away',\n",
       " 'Pulling Hand In',\n",
       " 'Sliding Two Fingers Left',\n",
       " 'Sliding Two Fingers Right',\n",
       " 'Sliding Two Fingers Down',\n",
       " 'Sliding Two Fingers Up',\n",
       " 'Pushing Two Fingers Away',\n",
       " 'Pulling Two Fingers In',\n",
       " 'Rolling Hand Forward',\n",
       " 'Rolling Hand Backward',\n",
       " 'Turning Hand Clockwise',\n",
       " 'Turning Hand Counterclockwise',\n",
       " 'Zooming In With Full Hand',\n",
       " 'Zooming Out With Full Hand',\n",
       " 'Zooming In With Two Fingers',\n",
       " 'Zooming Out With Two Fingers',\n",
       " 'Thumb Up',\n",
       " 'Thumb Down',\n",
       " 'Shaking Hand',\n",
       " 'Stop Sign',\n",
       " 'Drumming Fingers',\n",
       " 'No gesture',\n",
       " 'Doing other things']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path = load_all_path(root)\n",
    "labels = np.genfromtxt('../../jester/jester-v1-labels.csv', delimiter=',', dtype=np.str)\n",
    "labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a random location or at the center location.\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mode):\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            paths (list): paths to be cropped.\n",
    "        Returns:\n",
    "            list: Cropped paths.\n",
    "        \"\"\"\n",
    "        num_frames = len(path)\n",
    "        \n",
    "        if self.mode == 'random':\n",
    "            if num_frames < self.size:\n",
    "                pad_before = (self.size - num_frames)//2\n",
    "                pad_after = self.size - num_frames - pad_before\n",
    "                new_path = [path[0]]*pad_before + path + [path[-1]]*pad_after\n",
    "            else:\n",
    "                begin_index = random.randint(0, num_frames - self.size)\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "        else:\n",
    "            if num_frames < self.size:\n",
    "                pad_before = (self.size - num_frames)//2\n",
    "                pad_after = self.size - num_frames - pad_before\n",
    "                new_path = [path[0]]*pad_before + path + [path[-1]]*pad_after\n",
    "            else:\n",
    "                begin_index = (num_frames - self.size)//2\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "        \n",
    "        return new_path\n",
    "\n",
    "    \n",
    "class MultiScaleRandomCrop(object):\n",
    "\n",
    "    def __init__(self, scales, size, interpolation=Image.BILINEAR):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_random_param(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.topleft_x = random.random()\n",
    "        self.topleft_y = random.random()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width, image_height = _get_image_size(img)\n",
    "        min_length = min(image_width, image_height)\n",
    "        crop_size = int(min_length * self.scale)\n",
    "\n",
    "        topleft_x = self.topleft_x * (image_width - crop_size)\n",
    "        topleft_y = self.topleft_y * (image_height - crop_size)\n",
    "        bottomright_x = topleft_x + crop_size\n",
    "        bottomright_y = topleft_x + crop_size\n",
    "\n",
    "        img = F.crop(img, topleft_x, topleft_y, bottomright_x, bottomright_y)\n",
    "        img = F.resize(img, self.size, self.interpolation)\n",
    "\n",
    "        return img\n",
    "\n",
    "# class SpatialElasticDisplacement(object):\n",
    "\n",
    "#     def __init__(self, sigma=2.0, alpha=1.0, order=0, cval=0, mode=\"constant\"):\n",
    "#         self.alpha = alpha\n",
    "#         self.sigma = sigma\n",
    "#         self.order = order\n",
    "#         self.cval = cval\n",
    "#         self.mode = mode\n",
    "    \n",
    "#         @staticmethod\n",
    "#     def get_random_param(self):\n",
    "#         self.p = random.random()\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         if self.p < 0.50:\n",
    "#             is_L = False\n",
    "#             is_PIL = isinstance(img, Image.Image)\n",
    "            \n",
    "#             if is_PIL:\n",
    "#                 img = np.asarray(img, dtype=np.uint8)\n",
    "#             if len(img.shape) == 2:\n",
    "#                 is_L = True\n",
    "#                 img = np.reshape(img, img.shape + (1,))  \n",
    "\n",
    "#             image = img\n",
    "#             image_first_channel = np.squeeze(image[..., 0])\n",
    "#             indices_x, indices_y = self._generate_indices(image_first_channel.shape, alpha=self.alpha, sigma=self.sigma)\n",
    "#             ret_image = (self._map_coordinates(\n",
    "#                 image,\n",
    "#                 indices_x,\n",
    "#                 indices_y,\n",
    "#                 order=self.order,\n",
    "#                 cval=self.cval,\n",
    "#                 mode=self.mode))\n",
    "\n",
    "#             if  is_PIL:\n",
    "#                 if is_L:\n",
    "#                     return Image.fromarray(ret_image.reshape(ret_image.shape[:2]), mode= 'L')\n",
    "#                 else:\n",
    "#                     return Image.fromarray(ret_image)\n",
    "#             else:\n",
    "#                 return ret_image\n",
    "#         else:\n",
    "#             return img\n",
    "\n",
    "#     def _generate_indices(self, shape, alpha, sigma):\n",
    "#         assert (len(shape) == 2),\"shape: Should be of size 2!\"\n",
    "#         dx = scipy.ndimage.gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "#         dy = scipy.ndimage.gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "#         x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "#         return np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1))\n",
    "\n",
    "#     def _map_coordinates(self, image, indices_x, indices_y, order=1, cval=0, mode=\"constant\"):\n",
    "#         assert (len(image.shape) == 3),\"image.shape: Should be of size 3!\"\n",
    "#         result = np.copy(image)\n",
    "#         height, width = image.shape[0:2]\n",
    "#         for c in range(image.shape[2]):\n",
    "#             remapped_flat = scipy.ndimage.interpolation.map_coordinates(\n",
    "#                 image[..., c],\n",
    "#                 (indices_x, indices_y),\n",
    "#                 order=order,\n",
    "#                 cval=cval,\n",
    "#                 mode=mode\n",
    "#             )\n",
    "#             remapped = remapped_flat.reshape((height, width))\n",
    "#             result[..., c] = remapped\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(paths, mode):\n",
    "    all_image = []\n",
    "    temporal_transform = TemporalCrop(sample_duration, mode)\n",
    "    if mode == 'train':\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            MultiScaleRandomCrop(scales, sample_size),\n",
    "    #         SpatialElasticDisplacement(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "    else:\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(sample_size),\n",
    "            transforms.CenterCrop(sample_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "                \n",
    "    new_paths = temporal_transform(paths)\n",
    "    for path in new_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = spatial_transform(image)\n",
    "        all_image.append(image)\n",
    "    video = np.stack(all_image).transpose(1,0,2,3)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_idx(index):\n",
    "    if index == 25 or index == 26:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, all_path, x, y, mode):\n",
    "        self.length = len(x)\n",
    "        self.all_path = all_path\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.length)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            x = read_video(self.all_path[int(self.x[index,0])-1], 'random')\n",
    "            y = map_idx(int(np.argwhere(self.y == self.x[index,1])))\n",
    "            return torch.from_numpy(x), torch.tensor(y)\n",
    "        elif self.mode == 'valid':\n",
    "            x = read_video(self.all_path[int(self.x[index,0])-1], 'center')\n",
    "            y = map_idx(int(np.argwhere(self.y == self.x[index,1])))\n",
    "            return torch.from_numpy(x), torch.tensor(y)\n",
    "        else:\n",
    "            x = read_video(self.all_path[int(self.x[index])-1], 'center')\n",
    "            return torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt('../../jester/jester-v1-validation.csv', delimiter=';', dtype=np.str)    \n",
    "train_data = Dataset(all_path, train, labels, 'train')\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.genfromtxt('../../jester/jester-v1-validation.csv', delimiter=';', dtype=np.str)\n",
    "valid_data = Dataset(all_path, valid, labels, 'valid')\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.genfromtxt('../../jester/jester-v1-test.csv', delimiter=';', dtype=np.str)\n",
    "test_data = Dataset(all_path, test, labels, 'test')\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (data, target) in enumerate(train_loader):\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_training_set(opt, spatial_transform, temporal_transform,\n",
    "#                      target_transform):\n",
    "#     assert opt.dataset in ['jester', 'egogesture', 'nv']\n",
    "\n",
    "#     if opt.train_validate:\n",
    "#         subset = ['training', 'validation']\n",
    "#     else:\n",
    "#         subset = 'training'\n",
    "#     if opt.dataset == 'jester':\n",
    "#         training_data = Jester(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             subset,\n",
    "#             spatial_transform=spatial_transform,\n",
    "#             temporal_transform=temporal_transform,\n",
    "#             target_transform=target_transform,\n",
    "#             sample_duration=opt.sample_duration,\n",
    "#             modality=opt.modality)\n",
    "#     elif opt.dataset == 'egogesture':\n",
    "#         training_data = EgoGesture(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             subset,\n",
    "#             spatial_transform=spatial_transform,\n",
    "#             temporal_transform=temporal_transform,\n",
    "#             target_transform=target_transform,\n",
    "#             sample_duration=opt.sample_duration,\n",
    "#             modality=opt.modality)\n",
    "#     elif opt.dataset == 'nv':\n",
    "#         training_data = NV(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             subset,\n",
    "#             spatial_transform=spatial_transform,\n",
    "#             temporal_transform=temporal_transform,\n",
    "#             target_transform=target_transform,\n",
    "#             sample_duration=opt.sample_duration,\n",
    "#             modality=opt.modality)\n",
    "#     return training_data\n",
    "\n",
    "\n",
    "# def get_validation_set(opt, spatial_transform, temporal_transform,\n",
    "#                        target_transform):\n",
    "#     assert opt.dataset in ['jester', 'egogesture', 'nv']\n",
    "\n",
    "#     if opt.dataset == 'jester':\n",
    "#         validation_data = Jester(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             'validation',\n",
    "#             opt.n_val_samples,\n",
    "#             spatial_transform,\n",
    "#             temporal_transform,\n",
    "#             target_transform,\n",
    "#             modality=opt.modality,\n",
    "#             sample_duration=opt.sample_duration)\n",
    "#     elif opt.dataset == 'egogesture':\n",
    "#         validation_data = EgoGesture(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             'validation',\n",
    "#             opt.n_val_samples,\n",
    "#             spatial_transform,\n",
    "#             temporal_transform,\n",
    "#             target_transform,\n",
    "#             modality=opt.modality,\n",
    "#             sample_duration=opt.sample_duration)\n",
    "#     elif opt.dataset == 'nv':\n",
    "#         validation_data = NV(\n",
    "#             opt.video_path,\n",
    "#             opt.annotation_path,\n",
    "#             'validation',\n",
    "#             spatial_transform=spatial_transform,\n",
    "#             temporal_transform=temporal_transform,\n",
    "#             target_transform=target_transform,\n",
    "#             sample_duration=opt.sample_duration,\n",
    "#             modality=opt.modality)\n",
    "#     return validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.isDownSample = downsample\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        \n",
    "        if self.isDownSample:\n",
    "            self.downconv = conv1x1x1(inplanes, planes, stride)\n",
    "            self.downnorm = nn.BatchNorm3d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.isDownSample:\n",
    "            residual = self.downconv(residual)\n",
    "            residual = self.downnorm(residual)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet10(nn.Module):\n",
    "    def __init__(self, num_classes, depth, width, length):\n",
    "        super(resnet10, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.length = length\n",
    "        self.conv1 = nn.Conv3d(3, 8, kernel_size=7,stride=(1, 2, 2),padding=(3, 3, 3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(8)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        \n",
    "        self.block2 = BasicBlock(8, 16, stride=2, downsample=True)\n",
    "        self.block3 = BasicBlock(16, 32, stride=2, downsample=True)\n",
    "        self.block4 = BasicBlock(32, 64, stride=2, downsample=True)\n",
    "        self.block5 = BasicBlock(64, 128, stride=2, downsample=True)\n",
    "        last_duration = int(math.ceil(self.depth / 32))\n",
    "        last_width = int(math.ceil(self.width / 64))\n",
    "        last_length = int(math.ceil(self.length / 64))\n",
    "        self.avgpool = nn.AvgPool3d((last_duration, last_width, last_length), stride=1)\n",
    "        \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.block5(out)\n",
    "        #print(out.shape)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.squeeze(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet10(\n",
       "  (conv1): Conv3d(3, 8, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (maxpool1): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (block2): BasicBlock(\n",
       "    (conv1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downconv): Conv3d(8, 16, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (downnorm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (block3): BasicBlock(\n",
       "    (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downconv): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (downnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (block4): BasicBlock(\n",
       "    (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downconv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (downnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (block5): BasicBlock(\n",
       "    (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downconv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (downnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.5.0', 'resnext50_32x4d', pretrained=True)\n",
    "model = resnet10(num_classes=num_classes, depth=16, width=224, length=224)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor=0.1, patience=2)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    itr = tqdm(train_loader)\n",
    "    for data in itr:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        #print(i, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    print('Training Loss: ', running_loss)\n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels).detach()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Validation Loss: ', running_loss)\n",
    "        print('Validation Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51317c5e1a9442891073a25a63e7c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3697.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.39790617815862\n",
      "Training Accuracy:  86.46784337593833 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656987df989640d8a473a2089094890b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3697.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "Train_loss = []\n",
    "Train_acc = []\n",
    "Valid_loss = []\n",
    "Valid_acc = []\n",
    "num_no_improve = 0\n",
    "for i in range(n_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = test_model(model, valid_loader, criterion)\n",
    "    Train_acc.append(train_acc)\n",
    "    Train_loss.append(train_loss)\n",
    "    Valid_loss.append(valid_loss)\n",
    "    scheduler.step(valid_loss)\n",
    "    print('='*40)\n",
    "\n",
    "    if i == 0:\n",
    "        torch.save(model.state_dict(), 'project.pth')\n",
    "    else:\n",
    "        if test_acc > max(Test_acc):\n",
    "            torch.save(model.state_dict(), 'project.pth')\n",
    "            num_no_improve = 0\n",
    "        else:\n",
    "            num_no_improve += 1\n",
    "    Valid_acc.append(valid_acc)\n",
    "    \n",
    "    training_loss = np.array(Train_loss).reshape(-1,1)\n",
    "    training_acc = np.array(Train_acc).reshape(-1,1)\n",
    "    validation_loss = np.array(Valid_loss).reshape(-1,1)\n",
    "    validation_acc = np.array(Valid_acc).reshape(-1,1)\n",
    "    result = np.concatenate([training_loss, training_acc, validation_loss, validation_acc]).T\n",
    "    np.savetxt('result_project.csv', result, delimiter=',', fmt='%1.5f', header='training_loss,training_acc,validation_loss,validation_acc', comments='')\n",
    "    \n",
    "    if num_no_improve >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
